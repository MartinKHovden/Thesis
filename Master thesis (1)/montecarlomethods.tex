% \section{Monte Carlo methods}
Monte Carlo methods is a general term for a broad range of algorithms that relies on random draws from a target probability distribution. The draws are often used to calculate an approximation of a quantity of interest. There are three main areas where Monte Carlo methods are used; optimization, integration, and drawing random samples from a random distribution. Monte Carlo methods are heavily used in the physical sciences. Mainly to estimate high dimensional integrals that would be impossible to solve with other analytical or numerical methods. 
\\
\\
The main reason for using Monte Carlo methods are that  
\\
\\
As a simple example, we can use Monte Carlo methods to calculate the value of $\pi$. Lets say we are able to draw uniformly distributed samples on the closed interval $[0,1]$. We now sample N pairs of x and y values, and let each pair of values be denoted by $x_i$ and $y_i$ for $i=1,...,N$. For each pair, we calculate if it is inside or outside of the unit-circle. For each pair inside of the unit-circle we increment the variable K by one. K is initialized to zero. $\pi$ can then be approximated by the formula
\begin{equation}
    \pi \approx 4\frac{K}{N}
\end{equation}
In figure \ref{fig:pi_approx} the relative error is shown as a function of N. The error increase with N except for small values of N where the approximation sometimes can be less stable. 

\section{Monte Carlo Integration}
Monte Carlo integration is a non-deterministic numerical method for solving definite integrals \cite{compstat}. The main idea is to use a random number generator to draw random numbers where the function value is evaluated. An approximation of the integral value is then found by calculating the mean of all the random function values. The non-deterministic nature of the method implies that we will get different results from each approximation. In general, the more random samples we use, the better the approximation becomes. There also exist more advanced methods that converges to the exact solution more rapidly by drawing the random numbers from a more appropriate distribution. One such method is presented later, and is called importance sampling. 
\\
\\
More formally, the expected value of a function can be approximated by 
\begin{equation}
    E[f(\boldsymbol{x})] = \int f(x)p(x)dx \approx \frac{1}{N}\sum_{i=1}^N f(X_i) = \hat{\mu}, 
    \label{eq:MonteCarloIntegration}
\end{equation}
where $X_i$ is drawn from the probability distribution p \cite{compstat}. By adjusting N it is possible to increase the accuracy of the Monte Carlo integration, and it can be shown that 
\begin{equation}
    \lim_{n\to \infty} \frac{1}{N}\sum_{i=1}^N f(x_i) = E[f(\boldsymbol{x})]
\end{equation}
by the law of large numbers \cite{compstat}.
\\
\\
When working with random numbers and Monte Carlo methods it is interesting to see how good the estimate of a parameter is. This can be done by calculating the variance of the estimator. The sampling variance of $\hat{\mu}$ can then be calculated using
\begin{equation}
    \hat{\text{Var}}(\hat{\mu}) =  \frac{1}{N-1}\sum_{i=1}^N (f(X_i) - \hat{\mu})^2.
    \label{eq:MonteCarloIntegrationVariance}
\end{equation}
where we assume that the samples are uncorrelated \cite{compstat}. 
Using equations \ref{eq:MonteCarloIntegration} and \ref{eq:MonteCarloIntegrationVariance} and adapting them to the quantum system, the energy estimate and the variance of the energy estimate can be calculated using
\begin{equation}
    E[H(\alpha)] = \frac{1}{N}\sum_{i=1}^N E_L(\boldsymbol{r_i})
\end{equation}
and 
\begin{equation}
    \text{Var}(E[H(\alpha)]) = \frac{1}{N-1}\sum_{i=1}^N (E_L(\boldsymbol{r_i}) - E[H(\alpha)]^2) = \frac{1}{N-1}\text{Var}(E_L)
\end{equation}
where $\boldsymbol{r_i}$ is the coordinates of the i'th particle and N is the number of samples. The problem is that the samples of the local energy is not uncorrelated. This is because the current position is dependent on the previous position. A better method for estimating the variance is called blocking and will be presented in a later section. 


\section{Markov Chain Monte Carlo}
Markov Chain Monte Carlo methods are used for sampling from a distribution f. We are often interested in using MCMC when it is hard to sample from f, but it is easy to calculate the value of f at each point. 
\\
\\
The idea is to create a sequence of samples that converge towards the target distribution f. This is done by making an irreducible and  aperiodic Markov chain with a limiting distribution equal to f \cite{compstat}. The samples $\{X^{(t)}\}$ from the Markov Chain can then be used to calculate expectation values of functions. There are different ways to create such a chain. In this section 3 different methods are presented. For a more theoretical background on the methods, see the lecture notes from FYS3150 \cite{mhj_book} or the report for the VMC project \cite{4411}. The 3 methods are the Metropolis Brute-Force sampling, Metropolis Importance sampling, and Gibbs sampling. 
\subsection{Metropolis Hastings}
The Metropolis algorithm has been ranked as one of the most important algorihtms in the last 100 years (???). It builds on the idea behind detailed balance. Detailed balance means that
\begin{equation}
    p(y)P(x|y) = p(x)P(y|x)
\end{equation}
or something. 
The Metropolis Hastings algorithm goes as follows \cite{compstat},
\begin{itemize}
    \item Sample an initial point $\boldsymbol{X^{(0)}}$ from an initial distribution. 
    \item for t = 0,...,N:
    \begin{itemize}
        \item Sample a proposal value $\boldsymbol{X^*}$ from a proposal distribution $p(\cdot | \boldsymbol{x}^{(t)})$ for updating one randomly chosen coordinate.
        \item Evaluate the Metropolis acceptance ratio 
        \begin{equation}
            R(\boldsymbol{x^{(t)}, \boldsymbol{X}^*}) = \frac{f(\boldsymbol{X}^*)p(\boldsymbol{x^{(t)}}|\boldsymbol{X}^*)}{f(\boldsymbol{x}^{(t)})p(\boldsymbol{X}^*|\boldsymbol{x}^{(t)})}
        \end{equation}
        \item Sample U from $\text{Uniform}(0,1)$
        \item Set the new sampled value to be the proposal value $\boldsymbol{X}^*$ if $U < R$.
        \item Set the new sampled value equal to the previous value $\boldsymbol{x}^{(t)}$ if $U > R$.
    \end{itemize}
\end{itemize}
For the brute-force version, a random walk chain is used. This means that the proposed value is samples from
\begin{equation}
    \boldsymbol{X}^{(t+1)} = \boldsymbol{X}^{(t)} + \Delta x\cdot\epsilon
\end{equation}
where $\Delta x$ is the step length and $\epsilon$ is random variable \cite{compstat}. The random variable can for example be drawn from the uniform distribution between -1 and 1 or from a standard normal distribution. This is a simple method for proposing new steps, but does not take into account information about the distribution. The initial value can for example be sampled from a Uniform or Gaussian distribution centered at zero.  
\\
\\
The metropolis ratio is given by
\begin{equation}
    R(\boldsymbol{x^{(t)}, \boldsymbol{X}^*}) = \frac{\uppsi(\boldsymbol{X}^*)}{\uppsi(\boldsymbol{x}^{(t)})}
\end{equation}
where the p disappears because of the symmetry of the proposal distribution. 

\subsection{Metropolis Importance Sampling}
Importance sampling is a variance reducing technique. 
The main problem with the brute force method, is that the proposal of a new step don't use information about the wave function. 
The difference between the Brute Force sampling and Importance sampling is how the algorithm proposes a new position, and how it calculates the Metropolis ratio. For a detailed background on the justification of the new transition distribution and ratio, see \cite{mhj_book}. The idea is to use a proposal distribution that use information about the wave function to move into areas with higher probability, as well as changing the Metropolis ratio to the so-called greens function ratio.  The Importance Sampling algorithm goes as follows \cite{mhj_vmc},
\begin{itemize}
    \item Sample an initial point $\boldsymbol{X^{(0)}}$ from an initial distribution. 
    \item for t = 0,...,N:
    \begin{itemize}
        \item Sample a proposal value $\boldsymbol{X^*} = \boldsymbol{x}^{(t)} + DF(\boldsymbol{x}^{(t)})\Delta t + \xi \sqrt{\Delta t}$ for one randomly chosen coordinate. D is the diffusion constant, $\Delta t$ is the importance time-step, and $\xi$ is a Gaussian random number. The drift force is given by
        \begin{equation}
            \boldsymbol{F} = 2\frac{1}{\uppsi}\nabla\uppsi
        \end{equation}
        \item Evaluate the Metropolis acceptance ratio 
        \begin{equation}
            q(\boldsymbol{X}^*, \boldsymbol{x}^{(t)}) = \frac{G(\boldsymbol{x}^{(t)}, \boldsymbol{X}^*, \Delta t) |\uppsi(\boldsymbol{X}^*)|^2 }{ G(\boldsymbol{X}^*, \boldsymbol{x}^{(t)}, \Delta t) |\uppsi(\boldsymbol{x}^{(t)})|^2 }
        \end{equation}
        \item Sample U from $\text{Uniform}(0,1)$
        \item Keep the proposal value $\boldsymbol{X}^*$ if $U < q$.
        \item Keep the previous value $\boldsymbol{x}^{(t)}$ if $U > q$.    \end{itemize}
\end{itemize}
Here, G is greens function, given by
\begin{equation}
    G(y,x,\Delta t) = \frac{1}{(4\pi D \Delta t)^{3N/2}}\exp{(-(y - x - D\Delta t F(x))2/4D\Delta t)}
\end{equation}

The main problem with the Brute-force metropolis algorithm is that the new steps are proposed according to a uniform distribution and does not account for the shape of the wave function. 
By introducing importance sampling the algorithm proposes more physically relevant steps, which means that the Markov Chain typically will converge to the equilibrium state faster. This can reduce the number of iterations needed for a certain accuracy drastically \cite{compstat}.  The idea is to choose samples that are more relevant to the system, i.e find positions where the particles are more likely to be according to the trial wave function. The main difference from the Metropolis algorithm is how we choose the new step, and the expression for the acceptance/rejection-ratio. 
\\
\\
The new method for sampling the proposed position comes from the Fokker-Planck equation, the Langevin equation and the idea about moving in the direction of the gradient of the wave function \cite{mhj}. The derivations are taken directly from the lecture notes by M. Hjorth-Jensen\cite{mhj}. 
\\
\\
The Fokker-Planck equation is given by
\begin{equation}
    \frac{\partial P}{\partial t} = D\frac{\partial}{\partial x}\bigg( \frac{\partial}{\partial x } -F \bigg)P(x,t),
\end{equation}
where F is the drift force and D is the diffusion constant \cite{mhj}.
The Fokker-Planck equation describes the development over time of a probability density function P(x,t). By setting the left side equal to zero we can show that 
\begin{equation}
    \frac{\partial^2 P}{\partial\boldsymbol{x}_i^2} = P\frac{\partial}{\partial \boldsymbol{x_i}}\boldsymbol{F_i}\frac{\partial }{\partial \boldsymbol{x_i}}P
\end{equation}
for all i\cite{mhj}. 
\\
\\
By letting the drift force be on the form $g(\boldsymbol{x})\frac{\partial P}{\partial \boldsymbol{x}}$, it can be shown that the drift force can be defined as 
\begin{equation}
    \boldsymbol{F} = 2\frac{1}{\uppsi_T}\nabla \uppsi_T \cite{mhj}.
\end{equation}
It is responsible for pushing the random walk into configurations where the particles actually have a higher probability of being. By using this drift-force the particles are moved towards a more desirable position \cite{mhj}. This is better compared to the uniform sampling in the brute-force metropolis algorithm since the system will tend to stay in more physically relevant positions. 
\\
\\
The new method for finding the next system configuration is found using the Langevin equation. The Langevin equation is given by 
\begin{equation}
    \frac{\partial x(t)}{\partial t} = DF(x(t)) + \eta
\end{equation}
where $\eta$ is a random variable. Solving this equation using Euler's method gives us the new update formula
\begin{equation}
    y = x + DF(x)\Delta t + \epsilon\sqrt{\Delta t}
\end{equation}
where $\Delta t$ is the time-step, $\epsilon$ is a random variable  and x is the current position \cite{mhj}. D is set to 0.5. When simulating the system $\Delta t$ have to chosen, typically in the intercal [0.001, 0.01] when calculating ground state energies \cite{mhj}. This have to be tested using trial and error.  
\\
\\
Solving the Fokker-Planck equation gives  Greens function 
\begin{equation}
    G(x,y, \Delta t) = \frac{1}{(4\pi D \Delta t) ^\frac{3N}{2}}\text{exp}(-(y-x-D\Delta t F(x))^2/4D \Delta t). 
\end{equation} \cite{mhj}
which can be used in the probabiliby ratio. 
As we will be working with multidimensional arrays, the squared in the exponential can be interpreted as the dot-product with itself. The interesting quantity is the ratio between the squared wave function of the new and the old position, but now the greens function ratio is also added to the equation. This gives the new transition probability ratio
\begin{equation}
    q(y,x) = \frac{ G(x,y, \Delta t) |\uppsi_T(y)|^2 }{ G(y,x,\Delta t) |\uppsi_T(x)|^2 }. \cite{mhj}
\end{equation}
\\
\\
By changing the update step for the position and the acceptance step in the brute-force Metropolis algorithm to the new ones, the importance sampling Metropolis algorithm samples as follows
\begin{itemize}
    \item Initialize the system with number of Monte Carlo cycles, choose an initial system configuration $\boldsymbol{R}$ and variational parameter $\alpha$, and then calculate the initial value $|\uppsi_T^\alpha(\boldsymbol{R})|^2$. $\uppsi_T^\alpha(\boldsymbol{R})$ is the trial wave function dependent on the variational parameter $\alpha$ and the position of the particles. 
    \item Initialize energies and variance, and for number of metropolis steps:
    \begin{itemize}
        \item Sample a new trial position, $\boldsymbol{R_p} = \boldsymbol{R} + D \boldsymbol{F(x)}\Delta t + \boldsymbol{\epsilon} \sqrt{\Delta t}$.
        \item Calculate q(\boldsymbol{R_p}, \boldsymbol{R}) as described above. 
        \item Sample a new random number u from an uniform distribution, $u \in [0,1]$. 
        \begin{itemize}
            \item If $w \geq u$, the new trial position is accepted.
            \item Else we reject the new trial position and continue the iterations with the old position. 
        \end{itemize}
        \item Sample the quantities of interest. In our case the local energy.
    \end{itemize}
    \item Then calculate the final total energy of the system and other desired values. 
\end{itemize}


% \subsection{Description of the System}
% In this article we study Variational Monte Carlo methods for calculating the ground state energy of a hard sphere Bode gas in various potential traps. The system is studied for various numbers of particles and dimensions for two different trial wave functions.
% \\
% \\
% The Hamiltonian used is given
% \begin{equation}
%     H = \sum_i^N \Big(\frac{\hbar^2}{2m}\nabla^2_i + V_{\text{ext}}(\boldsymbol{r_i}) \Big) + \sum_{i<j}^N V_{\text{int}}(\boldsymbol{r_i, r_j}),
% \end{equation}
% where 
% \begin{equation}
%     V_\text{ext} = 
%     \begin{cases}
%     \frac{1}{2}m\omega_{ho}^2r^2 & (S) \\
%     \frac{1}{2}m[\omega_{ho}^2(x^2 + y^2) + \omega_{z}^2z^2] & (E)
%     \end{cases}
% \end{equation}
% where (S) stands for spherical and (E) stands for elliptical. 
% \\
% \\
% We will study two different system. The first part will focus on the non-interacting case using the spherical potential. After that we will extend our methods to a system with interactions using the elliptical potential.
% The interaction potential $V_\text{int}$ is given by 
% \begin{equation}
%     V_\text{int}(r_{ij}) = 
%     \begin{cases}
%     \infty  & r_{ij} \leq a\\
%     0 & r_{ij} > a
%     \end{cases}
% \end{equation}
% where $r_{ij} = |\boldsymbol{r_i} - \boldsymbol{r_j}|$, the distance between particles i and j, and a is the hard-core diameter of the bosons. This potential is to prevent the particles from positioning themselves on top of each other.

% \subsection{Trial Wave Function}
% To get good estimates of the energy of the system, the trial wave function should be chosen so that it resembles the actual wave function of the system as close as possible \cite{mhj}. However, this is not necessarily easy, and some intuition about the system is required to make a good choice. 
% For this system we can use the trial wave function given by
% \begin{equation}
%     \uppsi(\boldsymbol{r}) = \uppsi(\boldsymbol{r_1,r_2},...,\boldsymbol{r_N}, \alpha, \beta) = \Big[\prod_i^N g(\alpha, \beta,  \boldsymbol{r_i})\Big]\Big[\prod_{j<k}^N f(a, |\boldsymbol{r}_{j} - \boldsymbol{r}_k|)\Big]
%     \label{eq::trialwavefunction}
% \end{equation}
% where N is the number of parameters, and $\alpha$  and $\beta$ are variational parameters. The first part of the expression is given by $g(\alpha, \beta, \boldsymbol{r_i}) = \text{exp}[-\alpha(x_i^2 + y_i^2 + \beta z_i^2)]$ and $\boldsymbol{r_i} = [x_i, y_i, z_i]^T$. The correlation wave function f is given by
% \begin{equation}
%     f(a, |\boldsymbol{r_j - r_k}|) = 
%     \begin{cases}
%     0 & |\boldsymbol{r}_j - \boldsymbol{r}_k| \leq a \\
%     (1 - \frac{a}{|\boldsymbol{r}_j - \boldsymbol{r}_k|}) & |\boldsymbol{r}_j - \boldsymbol{r}_k| > a,
%     \end{cases}
% \end{equation}
% \subsubsection{Non-interacting case in spherical trap}
% For the non-interacting wave function in a spherical trap, a = 0 and $\beta = 1$. The trial wave function then reduces to
% \begin{equation}
%     \uppsi(\boldsymbol{r}) = \uppsi(\boldsymbol{r_1,r_2},...,\boldsymbol{r_N}, \alpha, \beta) = \prod_i^N g(\alpha, \beta, \boldsymbol{r_i}).
% \end{equation}
% The Hamiltonian also simplifies to 
% \begin{equation}
%      H = \sum_i^N \Big(\frac{\hbar^2}{2m}\nabla^2_i + V_{\text{ext}}(\boldsymbol{r_i}) \Big)
% \end{equation}
% since the case where $r_{ij} < a$ never occurs. 
% The expression for the local energy for the non-interacting case with a spherical trap ($\beta = 1$) can easily be found analytically by finding the expression for the Laplacian of the trial wave function. Doing so gives the local energy,
% \begin{equation}
%     E_L(\boldsymbol{r}) = \frac{1}{\uppsi_T(\boldsymbol{r})}H\uppsi_T(\boldsymbol{r}) = \frac{\hbar^2}{2m}\bigg(-2\alpha N d + 4\alpha^2\sum_{i = 1}^N \sum_{j = 1}^d (x_i)_j^2\bigg) + \sum_i^N V_\text{ext}(\boldsymbol{r_i}), 
% \end{equation}
% where N is the number of particles in the system and d is the number of dimensions. Here $(x_j)_i$ is the j'th coordinate of the i'th particle and we will use $\hbar = m = 1$. 
% The expression then becomes
% \begin{equation}
%     E_L(\boldsymbol{r}) = \frac{1}{\uppsi_T(\boldsymbol{r})}H\uppsi_T(\boldsymbol{r}) = \bigg(\alpha N d + 4\alpha^2\sum_{i = 1}^N \sum_{j = 1}^d (x_i)_j^2\bigg) + \sum_i^N \frac{1}{2}\omega^2\boldsymbol{r_i}^2, 
% \end{equation}
% For a full derivation of the result, see the appendix. It is also possible to compute the local energy by using numerical derivatives for the first part of the Hamiltonian. For a discussion on numerical derivatives, see for example \cite{mhj}. In general, the first derivative can be found from 
% \begin{equation}
%     f'(x) = \frac{f(x+h) - f(x)}{h}
% \end{equation}
% and the second derivative 
% \begin{equation}
%     f''(x) = \frac{f(x-h) - 2f(x) + f(x+h)}{h^2}.
% \end{equation}
% \\
% \\
% The expression for the drift-force can similarly be derived with analytical techniques, which gives that 
% \begin{equation}
%     F = \frac{2\nabla_k \uppsi_T}{\uppsi_T} = 2\frac{\nabla_k\phi(\boldsymbol{r}_k)}{\phi(\boldsymbol{r}_k)}
% \end{equation}
% where $\nabla_k \phi(\boldsymbol{r_k}) = -2\alpha \boldsymbol{r_k} \phi(\boldsymbol{r_k})$ so the drift force with respect to the k'th particle is given by
% \begin{equation}
%      F = -4\alpha \boldsymbol{r_k}.
% \end{equation}
% For the non-interacting system in an spherical trap it is possible to find an analytical expression for the energy of the system. This is beneficial since the numerical methods can be tested and fine-tuned on those system before tackling more complicated system. The analytical expression is given by 
% \begin{equation}
%     E(\alpha) = \text{dim}\cdot N \cdot \frac{4\alpha^2 + 1}{8\alpha}.
% \end{equation}
% where dim is the number of dimensions, N is the number of particles, where $\hbar = m = 1$ \cite{griffiths}. The derivation of the expression can be found in the appendix.
% \\
% \\
% To find the ground state energy, we can minimize this expression. First finding the derivatie, which gives
% \begin{equation}
%     E'(\alpha) = \text{dim}\cdot N\cdot \frac{8^2\alpha^2 - (4\alpha^2 + 1)8}{8^2\alpha^2} = N\cdot \text{dim}\bigg(1 - \frac{32\alpha^2}{64\alpha^2}  + \frac{1}{8\alpha^2}\bigg). 
% \end{equation}
% Setting this equal to 0 and solving for $\alpha$ gives
% \begin{equation}
%     \alpha_\text{min} = 0.5,
% \end{equation}
% which is independent on the size of the system. 
% Inserting this gives the ground state energy
% \begin{equation}
%     E(\alpha_\text{min}) = \text{dim} \cdot N \cdot 0.5. 
% \end{equation}
% The energy is a linear function of N and dim. 
% \\
% \\
% The problem with using the system which do not include interactions is that the trial wave function don't include the interactions between particles. By including a correlation term the simulations can produce better results. 
% \subsubsection{Interacting case in elliptical trap}
% For the interacting case in a elliptical trap the trial wave function is the full expression in \ref{eq::trialwavefunction}. The energy can no longer be solved analytically for this trial wave function, so Monte Carlo integration is needed. The expression for the local energy is a bit harder to derive. The local energy is given by 
% \begin{multline}
%     E_L = \frac{1}{\uppsi_T(\boldsymbol{r})}H\uppsi_T(\boldsymbol{r}) = \sum_k^N \bigg( \frac{-\hbar^2}{2m}\frac{\nabla_k^2\uppsi_T}{\uppsi_T} + V_\text{ext}(\boldsymbol{r_k})\bigg) + \sum_{i<j}^N V_\text{int}(\boldsymbol{r_i, r_j}) = \\
%     \sum_k^N \Bigg( \frac{-\hbar^2}{2m}\Bigg[ \frac{\nabla_k^2\phi (\boldsymbol{r_k})}{\phi(\boldsymbol{r_k})} + 2 \frac{\nabla_k \phi(\boldsymbol{r_k})}{\phi(\boldsymbol{r_k})}\bigg( \sum_{j \neq k}u'(r_{kj})\frac{\boldsymbol{r_k} - \boldsymbol{r_j}}{r_{kj}}\bigg) + \\ \sum_{j \neq k}\bigg( u''(r_{kj}) + \frac{\text{dim - 1}}{r_{kj}}u'(r_{kj}) \bigg) +   \bigg(\sum_{j\neq k} u'(r_{kj})\frac{\boldsymbol{r_k} - \boldsymbol{r_j}}{r_{kj}}\bigg)^2 \Bigg] + V_\text{ext}(\boldsymbol{r_k})\Bigg) + \\ \sum_{i<j}^N V_\text{int}(\boldsymbol{r_i, r_j})
% \end{multline}
% Using the chain-rule it can be shown that
% \begin{equation}
%     u'(r_{jk}) =\frac{a}{(1-\frac{a}{r_{jk}})r_{jk}^2} 
% \end{equation}
% and 
% \begin{equation}
%     u''(r_{jk}) = \frac{-2r_{jk}a + a^2}{(r_{jk} - ar_{jk})^2}
% \end{equation}
% where the standard rule for derivatives of logarithms is used. 
% \\
% \\
% The drift force with respect to the k'th particle for the interacting case is given by 
% \begin{equation}
%     \boldsymbol{F} = \frac{\nabla_k\phi(\boldsymbol{r_k})}{\phi(\boldsymbol{r_k})} + \nabla_k\bigg(\sum_{j\neq k }u(r_{kj})\bigg).
% \end{equation}
% For a full derivation of the expressions, see the appendix.
% \\
% \\
% When working with the elliptical system, the first term in the drift-force and the local energy needs to account for the beta factor in front of the third dimension. The expression for the gradient in 3 dimensions
% \begin{equation}
%     \nabla_k \phi(\boldsymbol{r_k})= -2\alpha[x_k, y_k, \beta z_k]^T\phi(\boldsymbol{r_k})
% \end{equation}
% and the laplacian is given by
% \begin{equation}
%     \nabla_k \cdot \nabla_k \phi(\boldsymbol{r_k}) = -2\alpha\cdot(2 + \beta)\phi(\boldsymbol{r_k}) + 4\alpha^2\big(x_i^2 + y^2_i + \beta^2z_i\big)\phi(\boldsymbol{r_k})
% \end{equation}



\subsection{Gibbs Sampling}
An alternative sampling method is Gibbs sampling. The main difference is that the Gibbs sampler samples each dimension for every iteration instead of picking one randomly as in Metropolis. It is therefore well suited for multidimensional distributions \cite{compstat}. However, the method requires finding conditional distributions for all components of interest. 
\\
\\
As mentioned, the Gibbs sampler uses conditional distributions for sampling. For Gibbs sampling, an alternative wave function is used, $\uppsi(x) = \sqrt{F_{rbm}}$. Doing this leads to samples themselves being from the probability density $ |\uppsi(x)|^2$ \cite{extext}. The idea is to sample from a two step sample process where first the visible layers are updated, then the hidden layer is updated given the newly updated visible layer. The posterior distributions to sample from are given by
\begin{equation}
    P(\boldsymbol{X}|h) = \sum_i^M \mathcal{N}(X_i; a_i + \boldsymbol{w_ih}, \sigma^2) = \mathcal{N}(\boldsymbol{X};\boldsymbol{a} + \boldsymbol{Wh}, \sigma^2)
\end{equation}
and 
\begin{equation}
    P(H_j|\boldsymbol{x}) = \frac{e^{\left(b_j + \frac{\boldsymbol{x^Tw_{*j}}}{\sigma^2}\right)H_j}}{1 + e^{\left(b_j + \frac{\boldsymbol{x^Tw_{*j}}}{\sigma^2}\right)}}.
\end{equation}
where the last one can be written in vectorized form, 
\begin{equation}
    P(\boldsymbol{H}|\boldsymbol{x}) = \prod_j^N \frac{e^{\left(b_j + \frac{\boldsymbol{x^Tw_{*j}}}{\sigma^2}\right)H_j}}{1 + e^{\left(b_j + \frac{\boldsymbol{x^Tw_{*j}}}{\sigma^2}\right)}}
\end{equation} \cite{extext}.
The algorithm can be described as follows:
\begin{itemize}
    \item Choose some initial values for the visible layer $\boldsymbol{x}$ and the hidden layer $\boldsymbol{h}$
    \item for t=0,1,2..,N
    \begin{itemize}
        \item Update the visible layer given the values from the previous step
        \begin{equation}
            \boldsymbol{X}^{(t+1)}|\boldsymbol{h}^{(t)} \sim P(\boldsymbol{x}|\boldsymbol{h}^{(t)})
        \end{equation}
        \item Update the hidden layer given the values from the newly updated visible values: 
        \begin{equation}
            \boldsymbol{H}^{(t+1)}|\boldsymbol{x}^{(t+1)}  \sim P(\boldsymbol{h}|\boldsymbol{x}^{(t+1)})
        \end{equation}
        
    \end{itemize}
\end{itemize}
Note that there are no acceptance step as it was in the Metropolis sampling methods. For details on implementation, see the implementation part. 