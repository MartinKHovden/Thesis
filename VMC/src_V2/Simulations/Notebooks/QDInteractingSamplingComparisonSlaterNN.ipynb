{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5490196078431373, 0.33725490196078434, 0.29411764705882354, 1.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from pylab import cm\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "font_names = [f.name for f in fm.fontManager.ttflist]\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.size'] = 22\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "colors = cm.get_cmap('tab10', 3)\n",
    "print(colors(1))\n",
    "\n",
    "from numpy import log2, zeros, mean, var, sum, loadtxt, arange, array, cumsum, dot, transpose, diagonal, sqrt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "def block(x): \n",
    "    # preliminaries\n",
    "    n = len(x)\n",
    "    d = int(log2(n))\n",
    "    s, gamma = zeros(d), zeros(d)\n",
    "    mu = mean(x)\n",
    "\n",
    "    # estimate the auto-covariance and variances \n",
    "    # for each blocking transformation\n",
    "    for i in arange(0,d):\n",
    "        n = len(x)\n",
    "        # estimate autocovariance of x\n",
    "        gamma[i] = (n)**(-1)*sum( (x[0:(n-1)]-mu)*(x[1:n]-mu) )\n",
    "        # estimate variance of x\n",
    "        s[i] = var(x)\n",
    "        # perform blocking transformation\n",
    "        x = 0.5*(x[0:-1:2] + x[1::2])\n",
    "   \n",
    "    # generate the test observator M_k from the theorem\n",
    "    M = (cumsum( ((gamma/s)**2*2**arange(1,d+1)[::-1])[::-1] )  )[::-1]\n",
    "\n",
    "    # we need a list of magic numbers\n",
    "    q =array([6.634897,9.210340, 11.344867, 13.276704, 15.086272, 16.811894, 18.475307, 20.090235, 21.665994, 23.209251, 24.724970, 26.216967, 27.688250, 29.141238, 30.577914, 31.999927, 33.408664, 34.805306, 36.190869, 37.566235, 38.932173, 40.289360, 41.638398, 42.979820, 44.314105, 45.641683, 46.962942, 48.278236, 49.587884, 50.892181])\n",
    "\n",
    "    # use magic to determine when we should have stopped blocking\n",
    "    for k in arange(0,d):\n",
    "        if(M[k] < q[k]):\n",
    "            break\n",
    "    if (k >= d-1):\n",
    "        print(\"Warning: Use more data\")\n",
    "    return mu, s[k]/2**(d-k)\n",
    "\n",
    "\n",
    "def acceptance_ratio(e):\n",
    "    length = len(e)\n",
    "    accepted =  0\n",
    "    for i in range(1,length): \n",
    "        if e[i] != e[i-1]:\n",
    "            accepted += 1\n",
    "    print(accepted/length)\n",
    "    return accepted/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is22_1 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_1.0_numMCSteps_262144_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_1 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.1_numMCSteps_262144_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_01 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.01_numMCSteps_262144_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_001 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.001_numMCSteps_262144_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "\n",
    "is22 = [is22_1, is22_0_1, is22_0_01, is22_0_001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999961853027344\n",
      "0.9999961853027344\n",
      "0.9999961853027344\n",
      "0.9999961853027344\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " MC step-length &    Energy &       Var &  Acceptance ratio \\\\\n",
      "\\midrule\n",
      "          1.000 &  2.948432 &  0.000008 &          0.999996 \\\\\n",
      "          0.100 &  2.996853 &  0.000009 &          0.999996 \\\\\n",
      "          0.010 &  3.022168 &  0.000095 &          0.999996 \\\\\n",
      "          0.001 &  3.254571 &  0.003392 &          0.999996 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "energies = [block(sample)[0] for sample in is22]\n",
    "variances = [block(sample)[1] for sample in is22]\n",
    "acceptances = [acceptance_ratio(sample) for sample in is22]\n",
    "mc_step_lengths = [1.0, 0.1, 0.01, 0.001]\n",
    "\n",
    "df = pd.DataFrame({\"MC step-length\": mc_step_lengths,\"Energy\" : energies, \"Var\" : variances, \"Acceptance ratio\" : acceptances })\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "is22_1 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_1.0_numMCSteps_1048576_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_1 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.1_numMCSteps_1048576_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_01 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.01_numMCSteps_1048576_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "is22_0_001 = np.loadtxt(\"../Data/quantumDot/MC/Interacting/wf_slater_gaussian_nn_sysInfo_is_stepLength_0.001_numMCSteps_1048576_numDims_2_numParticles_2_elementinfo_slater_none_gaussian_none_nn_numhidden1_12_numhidden2_12_activationFunction_tanH_.txt\")\n",
    "\n",
    "is22 = [is22_1, is22_0_1, is22_0_01, is22_0_001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999990463256836\n",
      "0.9999990463256836\n",
      "0.9999990463256836\n",
      "0.9999990463256836\n",
      "\\begin{tabular}{rrrr}\n",
      "\\toprule\n",
      " MC step-length &    Energy &       Var &  Acceptance ratio \\\\\n",
      "\\midrule\n",
      "          1.000 &  2.936667 &  0.000002 &          0.999999 \\\\\n",
      "          0.100 &  2.990406 &  0.000002 &          0.999999 \\\\\n",
      "          0.010 &  3.009645 &  0.000012 &          0.999999 \\\\\n",
      "          0.001 &  3.187466 &  0.000660 &          0.999999 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "energies = [block(sample)[0] for sample in is22]\n",
    "variances = [block(sample)[1] for sample in is22]\n",
    "acceptances = [acceptance_ratio(sample) for sample in is22]\n",
    "mc_step_lengths = [1.0, 0.1, 0.01, 0.001]\n",
    "\n",
    "df = pd.DataFrame({\"MC step-length\": mc_step_lengths,\"Energy\" : energies, \"Var\" : variances, \"Acceptance ratio\" : acceptances })\n",
    "print(df.to_latex(index=False))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
